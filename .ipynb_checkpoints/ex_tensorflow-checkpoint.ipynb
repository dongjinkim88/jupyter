{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('tensorflow version: ' + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10825702 0.29029654 0.24277489 0.26624957 0.3376823  0.17250963\n",
      "  0.16434647 0.32546107 0.25885291 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.17479079\n",
      "  0.45664779 0.49428871 0.29248594 0.1988979  0.28028966 0.38471175\n",
      "  0.47603806 0.55636251 0.79067798 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00737531 0.10923028 0.48619968\n",
      "  0.49601398 0.372678   0.07514461 0.00526185 0.01601655 0.27784738\n",
      "  0.47603806 0.55636251 0.54594432 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.17700732 0.48291283 0.50629058\n",
      "  0.36020063 0.02746048 0.         0.         0.12279356 0.38471175\n",
      "  0.47603806 0.49478879 0.09883475 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.23077417 0.46648805 0.48291283 0.29332708\n",
      "  0.02755633 0.         0.         0.         0.28696322 0.38471175\n",
      "  0.47603806 0.17372584 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.28937621 0.44231716 0.45542509 0.33727245 0.01808181\n",
      "  0.         0.         0.00924857 0.08208485 0.3270046  0.38623839\n",
      "  0.24368615 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.5069794  0.5328197  0.44056887 0.32451343 0.         0.\n",
      "  0.         0.07061267 0.23237025 0.2651972  0.33634759 0.25800114\n",
      "  0.02077944 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.69709668 0.57875243 0.44056887 0.05531479 0.04215906 0.23908166\n",
      "  0.38775696 0.47271262 0.29248594 0.2651972  0.33501288 0.11755081\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.5069794  0.53052306 0.44056887 0.46648805 0.48291283 0.50629058\n",
      "  0.49601398 0.44329067 0.2624281  0.2651972  0.30831862 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12631501 0.41084795 0.46648805 0.41584161 0.27725436\n",
      "  0.082669   0.04707512 0.22196561 0.2651972  0.19086391 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12161071 0.29479808 0.26624957 0.14548368 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13926388 0.29248594 0.2651972  0.02802897 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.29248594 0.2651972  0.02802897 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13926388 0.29248594 0.2651972  0.02802897 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20791509 0.29248594 0.2651972  0.02802897 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08826584 0.29479808 0.26624957 0.02802897 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25202346 0.2651972  0.07474391 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11098281 0.2651972  0.25226069 0.06411863\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.01618499 0.19363605 0.33634759 0.25952777\n",
      "  0.02077944 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01473318 0.19620276 0.38471175\n",
      "  0.07933968 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.imshow(x_test[1], cmap=plt.cm.binary)\n",
    "# plt.imshow(x_test[2])\n",
    "plt.imshow(x_train[4])\n",
    "plt.show()\n",
    "print(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid keyword argument(s) in `compile`: {'matrics'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1bad59a93f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m model.compile(optimizer='adam', \n\u001b[1;32m      8\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m               matrics=['accuracy'])\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m           \u001b[0msteps_per_execution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'experimental_steps_per_execution'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_eagerly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_validate_compile\u001b[0;34m(self, optimizer, metrics, **kwargs)\u001b[0m\n\u001b[1;32m   2518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minvalid_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2519\u001b[0m       raise TypeError('Invalid keyword argument(s) in `compile`: %s' %\n\u001b[0;32m-> 2520\u001b[0;31m                       (invalid_kwargs,))\n\u001b[0m\u001b[1;32m   2521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2522\u001b[0m     \u001b[0;31m# Model must be created and compiled with the same DistStrat.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid keyword argument(s) in `compile`: {'matrics'}"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              matrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0907\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3452f7a38776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([x_test])\n",
    "#print(prediction)\n",
    "import numpy as np\n",
    "print(np.argmax(prediction[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
